{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of Height: 1.584962498412875\n",
      "Entropy of Weight: 1.584962498412875\n",
      "Joint Entropy of Height and Weight: 3.0361108064663624\n",
      "Conditional Entropy H(Weight|Height): 1.451148308053487\n",
      "Information Gain (Height -> Weight): 0.1338141903593879\n",
      "Mutual Information between Height and Weight: 0.13381419035938746\n",
      "Gini Index of Weight: 0.6666666656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANANT TIWARI\\AppData\\Local\\Temp\\ipykernel_18272\\3930543648.py:5: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return -np.sum(p * np.log2(p) if p > 0 else 0\n"
     ]
    }
   ],
   "source": [
    "def entropy(labels):\n",
    "    total_count = len(labels)\n",
    "    label_counts = Counter(labels)\n",
    "    probabilities = [count / total_count for count in label_counts.values()]\n",
    "    return -np.sum(p * np.log2(p) if p > 0 else 0 \n",
    "                  for p in probabilities)\n",
    "\n",
    "# Function to compute joint entropy\n",
    "# def joint_entropy(X, Y):\n",
    "#     joint_labels = list(zip(X, Y))\n",
    "#     joint_labels\n",
    "#     return entropy(joint_labels)\n",
    "\n",
    "# def joint_entropy(X, Y):\n",
    "#     mp={}\n",
    "#     length= len(X)*len(Y)\n",
    "#     for x in X:\n",
    "#         for y in Y:\n",
    "#             if (x,y) not in mp:\n",
    "#                 mp[(x,y)]=0\n",
    "#             mp[(x,y)]+=1\n",
    "    \n",
    "#     joint_entropy_res=0\n",
    "    \n",
    "#     for k,v in mp.items():\n",
    "#         probab= v/length\n",
    "#         probab=probab*log2(probab)\n",
    "#         joint_entropy_res+= probab\n",
    "    \n",
    "#     return joint_entropy_res\n",
    "\n",
    "def joint_entropy(X, Y):\n",
    "    mp = {}\n",
    "    length = len(X)  # Length should be the number of samples (assuming X and Y have the same length)\n",
    "    \n",
    "    # Count occurrences of each (x, y) pair\n",
    "    for x, y in zip(X, Y):\n",
    "        if (x, y) not in mp:\n",
    "            mp[(x, y)] = 0\n",
    "        mp[(x, y)] += 1\n",
    "    \n",
    "    joint_entropy_res = 0\n",
    "    \n",
    "    # Calculate joint entropy\n",
    "    for v in mp.values():\n",
    "        probab = v / length\n",
    "        joint_entropy_res -= probab * log2(probab)  # Apply the correct entropy formula\n",
    "    \n",
    "    return joint_entropy_res\n",
    "            \n",
    "            \n",
    "# def joint_entropy(x, y):\n",
    "#     joint_probs = np.histogram2d(x, y, bins=[len(np.unique(x)), len(np.unique(y))], density=True)[0]\n",
    "#     joint_probs = joint_probs[joint_probs > 0]\n",
    "#     return entropy(joint_probs)\n",
    "\n",
    "# Function to compute conditional entropy H(Y|X)\n",
    "def conditional_entropy(X, Y):\n",
    "    total_count = len(X)\n",
    "    unique_x = set(X)\n",
    "    \n",
    "    cond_entropy = 0\n",
    "    for x_val in unique_x:\n",
    "        indices = [i for i in range(total_count) if X[i] == x_val]\n",
    "        sub_Y = [Y[i] for i in indices]\n",
    "        prob_x = len(indices) / total_count\n",
    "        cond_entropy += prob_x * entropy(sub_Y)\n",
    "    return cond_entropy\n",
    "\n",
    "# Function to compute information gain\n",
    "def information_gain(X, Y):\n",
    "    return entropy(Y) - conditional_entropy(X, Y)\n",
    "\n",
    "# Function to compute mutual information I(X;Y)\n",
    "def mutual_information(X, Y):\n",
    "    return entropy(X) + entropy(Y) - joint_entropy(X, Y)\n",
    "\n",
    "# Function to compute Gini index\n",
    "def gini_index(labels):\n",
    "    total_count = len(labels)\n",
    "    label_counts = Counter(labels)\n",
    "    probabilities = [count / total_count for count in label_counts.values()]\n",
    "    return 1 - sum(p ** 2 for p in probabilities)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    data=pd.read_csv('SOCR-HeightWeight (1).csv')\n",
    "    height = data['Height(Inches)'].tolist()\n",
    "    weight = data['Weight(Pounds)'].tolist()\n",
    "\n",
    "    # Discretize the data for entropy-based calculations\n",
    "    # height =sorted(height)\n",
    "    # ok=0\n",
    "\n",
    "    \n",
    "    height_discretized = pd.qcut(height, q=3, labels=[0, 1, 2]).tolist()\n",
    "    weight_discretized = pd.qcut(weight, q=3, labels=[0, 1, 2]).tolist()\n",
    "    \n",
    "    # for i in height_discretized:\n",
    "    #     if i==2:\n",
    "    #         ok+=1\n",
    "    \n",
    "    # print(ok)\n",
    "    \n",
    "    # print(height_discretized)\n",
    "\n",
    "    print(\"Entropy of Height:\", entropy(height_discretized))\n",
    "    print(\"Entropy of Weight:\", entropy(weight_discretized))\n",
    "    print(\"Joint Entropy of Height and Weight:\", joint_entropy(height_discretized, weight_discretized))\n",
    "    print(\"Conditional Entropy H(Weight|Height):\", conditional_entropy(height_discretized, weight_discretized))\n",
    "    print(\"Information Gain (Height -> Weight):\", information_gain(height_discretized, weight_discretized))\n",
    "    print(\"Mutual Information between Height and Weight:\", mutual_information(height_discretized, weight_discretized))\n",
    "    print(\"Gini Index of Weight:\", gini_index(weight_discretized))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
